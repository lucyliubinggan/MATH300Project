{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1831b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rk</th>\n",
       "      <th>code</th>\n",
       "      <th>cfo2cl</th>\n",
       "      <th>dta2ev</th>\n",
       "      <th>NNP_SD</th>\n",
       "      <th>ocfa4q</th>\n",
       "      <th>r_nta</th>\n",
       "      <th>roic4q</th>\n",
       "      <th>yoy_s</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945.0</td>\n",
       "      <td>000004</td>\n",
       "      <td>-0.539357</td>\n",
       "      <td>-0.100045</td>\n",
       "      <td>-0.001195</td>\n",
       "      <td>-0.545248</td>\n",
       "      <td>-0.373964</td>\n",
       "      <td>-1.711607</td>\n",
       "      <td>0.285189</td>\n",
       "      <td>0.114401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1945.0</td>\n",
       "      <td>000005</td>\n",
       "      <td>-1.196494</td>\n",
       "      <td>-0.350442</td>\n",
       "      <td>-0.242075</td>\n",
       "      <td>-1.903597</td>\n",
       "      <td>-1.304091</td>\n",
       "      <td>-1.842590</td>\n",
       "      <td>0.416450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1945.0</td>\n",
       "      <td>000006</td>\n",
       "      <td>-1.569546</td>\n",
       "      <td>1.343961</td>\n",
       "      <td>2.317304</td>\n",
       "      <td>-1.987871</td>\n",
       "      <td>1.056031</td>\n",
       "      <td>0.439823</td>\n",
       "      <td>-2.245958</td>\n",
       "      <td>-0.077917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1945.0</td>\n",
       "      <td>000007</td>\n",
       "      <td>1.276299</td>\n",
       "      <td>-0.499103</td>\n",
       "      <td>-0.501018</td>\n",
       "      <td>2.723414</td>\n",
       "      <td>-1.013969</td>\n",
       "      <td>-1.625001</td>\n",
       "      <td>0.792931</td>\n",
       "      <td>-0.009745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1945.0</td>\n",
       "      <td>000009</td>\n",
       "      <td>-0.348548</td>\n",
       "      <td>-0.270275</td>\n",
       "      <td>0.043598</td>\n",
       "      <td>-0.184773</td>\n",
       "      <td>-0.233879</td>\n",
       "      <td>-0.161768</td>\n",
       "      <td>-0.313591</td>\n",
       "      <td>0.009129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108265</th>\n",
       "      <td>4477.0</td>\n",
       "      <td>688793</td>\n",
       "      <td>-0.855737</td>\n",
       "      <td>-2.272339</td>\n",
       "      <td>-0.464821</td>\n",
       "      <td>-1.076195</td>\n",
       "      <td>-0.982083</td>\n",
       "      <td>-1.067425</td>\n",
       "      <td>-1.258614</td>\n",
       "      <td>-0.138720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108266</th>\n",
       "      <td>4477.0</td>\n",
       "      <td>688798</td>\n",
       "      <td>0.685225</td>\n",
       "      <td>0.113780</td>\n",
       "      <td>0.200084</td>\n",
       "      <td>0.350019</td>\n",
       "      <td>-0.022114</td>\n",
       "      <td>0.117699</td>\n",
       "      <td>-0.778150</td>\n",
       "      <td>0.026701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108267</th>\n",
       "      <td>4477.0</td>\n",
       "      <td>688799</td>\n",
       "      <td>0.678994</td>\n",
       "      <td>-0.233143</td>\n",
       "      <td>-1.587911</td>\n",
       "      <td>0.085114</td>\n",
       "      <td>0.300693</td>\n",
       "      <td>0.106962</td>\n",
       "      <td>-0.537688</td>\n",
       "      <td>-0.052172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108268</th>\n",
       "      <td>4477.0</td>\n",
       "      <td>688800</td>\n",
       "      <td>-0.261622</td>\n",
       "      <td>0.404579</td>\n",
       "      <td>1.854591</td>\n",
       "      <td>-0.065149</td>\n",
       "      <td>0.876517</td>\n",
       "      <td>0.327391</td>\n",
       "      <td>1.797810</td>\n",
       "      <td>-0.047992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108269</th>\n",
       "      <td>4477.0</td>\n",
       "      <td>688819</td>\n",
       "      <td>-0.157889</td>\n",
       "      <td>2.511428</td>\n",
       "      <td>-0.915142</td>\n",
       "      <td>0.350509</td>\n",
       "      <td>0.511436</td>\n",
       "      <td>0.053357</td>\n",
       "      <td>0.076454</td>\n",
       "      <td>0.043528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5108270 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rk    code    cfo2cl    dta2ev    NNP_SD    ocfa4q     r_nta  \\\n",
       "0        1945.0  000004 -0.539357 -0.100045 -0.001195 -0.545248 -0.373964   \n",
       "1        1945.0  000005 -1.196494 -0.350442 -0.242075 -1.903597 -1.304091   \n",
       "2        1945.0  000006 -1.569546  1.343961  2.317304 -1.987871  1.056031   \n",
       "3        1945.0  000007  1.276299 -0.499103 -0.501018  2.723414 -1.013969   \n",
       "4        1945.0  000009 -0.348548 -0.270275  0.043598 -0.184773 -0.233879   \n",
       "...         ...     ...       ...       ...       ...       ...       ...   \n",
       "5108265  4477.0  688793 -0.855737 -2.272339 -0.464821 -1.076195 -0.982083   \n",
       "5108266  4477.0  688798  0.685225  0.113780  0.200084  0.350019 -0.022114   \n",
       "5108267  4477.0  688799  0.678994 -0.233143 -1.587911  0.085114  0.300693   \n",
       "5108268  4477.0  688800 -0.261622  0.404579  1.854591 -0.065149  0.876517   \n",
       "5108269  4477.0  688819 -0.157889  2.511428 -0.915142  0.350509  0.511436   \n",
       "\n",
       "           roic4q     yoy_s    return  \n",
       "0       -1.711607  0.285189  0.114401  \n",
       "1       -1.842590  0.416450  0.000000  \n",
       "2        0.439823 -2.245958 -0.077917  \n",
       "3       -1.625001  0.792931 -0.009745  \n",
       "4       -0.161768 -0.313591  0.009129  \n",
       "...           ...       ...       ...  \n",
       "5108265 -1.067425 -1.258614 -0.138720  \n",
       "5108266  0.117699 -0.778150  0.026701  \n",
       "5108267  0.106962 -0.537688 -0.052172  \n",
       "5108268  0.327391  1.797810 -0.047992  \n",
       "5108269  0.053357  0.076454  0.043528  \n",
       "\n",
       "[5108270 rows x 10 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"/Users/ericsmac/Documents/MATH300Project/data\")\n",
    "df = pd.read_feather('merged_factors.ft')\n",
    "ocfa4q = pd.read_feather('ocfa4q.ft')\n",
    "ocfa4q = ocfa4q[['rk','code','return']]\n",
    "df = df.merge(ocfa4q, on=['code','rk'], how = 'left')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834c6d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 20:44:16.908281: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0434323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed79672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_loss(y_true, y_pred):\n",
    "    \"\"\"Loss = 1 – Pearson correlation\"\"\"\n",
    "    x = y_pred\n",
    "    y = y_true\n",
    "\n",
    "    # Normalize\n",
    "    x -= tf.reduce_mean(x)\n",
    "    y -= tf.reduce_mean(y)\n",
    "\n",
    "    # Compute correlation\n",
    "    corr = tf.reduce_sum(x * y) / (tf.sqrt(tf.reduce_sum(tf.square(x))) *\n",
    "                                   tf.sqrt(tf.reduce_sum(tf.square(y))) + 1e-8)\n",
    "\n",
    "    # We want to MINIMIZE the loss, so return 1 - corr\n",
    "    return 1 - corr\n",
    "\n",
    "def correlation_metric(y_true, y_pred):\n",
    "    x = y_pred - tf.reduce_mean(y_pred)\n",
    "    y = y_true - tf.reduce_mean(y_true)\n",
    "    corr = tf.reduce_sum(x * y) / (\n",
    "        tf.sqrt(tf.reduce_sum(tf.square(x))) *\n",
    "        tf.sqrt(tf.reduce_sum(tf.square(y))) + 1e-8\n",
    "    )\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55c6cf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 32)                256       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample training\n",
    "\n",
    "#Testing with sample set\n",
    "df_sample = df.sample(frac=0.2, random_state=42)\n",
    "feature_cols = ['cfo2cl', 'dta2ev', 'NNP_SD', 'ocfa4q', 'r_nta', 'roic4q', 'yoy_s']\n",
    "X = df_sample[feature_cols].values.astype('float32')\n",
    "y = df_sample['return'].values.astype('float32')\n",
    "\n",
    "# Train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)   # regression output: predicted return\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=correlation_loss,\n",
    "    metrics=[correlation_metric]  \n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ===========================\n",
    "# 5. Train the model\n",
    "# ===========================\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ===========================\n",
    "# 6. Evaluate on test set\n",
    "# ===========================\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Test MSE: {test_loss:.6f}, Test MAE: {test_mae:.6f}\")\n",
    "\n",
    "# ===========================\n",
    "# 7. Make predictions\n",
    "# ===========================\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "spearman_corr, pval = spearmanr(y_test, y_pred)\n",
    "print(f\"Test Spearman Corr: {spearman_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c61f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 977\n",
      "Trainable params: 977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 12:08:36.667259: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-12-09 12:08:36.748932: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12771/12771 [==============================] - ETA: 0s - loss: 1.0027 - correlation_metric: -0.0027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 12:10:57.129723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12771/12771 [==============================] - 155s 12ms/step - loss: 1.0027 - correlation_metric: -0.0027 - val_loss: 1.0143 - val_correlation_metric: -0.0143\n",
      "Epoch 2/10\n",
      "12771/12771 [==============================] - 154s 12ms/step - loss: 0.9766 - correlation_metric: 0.0235 - val_loss: 0.9974 - val_correlation_metric: 0.0026\n",
      "Epoch 3/10\n",
      "12771/12771 [==============================] - 154s 12ms/step - loss: 0.9718 - correlation_metric: 0.0282 - val_loss: 0.9943 - val_correlation_metric: 0.0057\n",
      "Epoch 4/10\n",
      "12771/12771 [==============================] - 154s 12ms/step - loss: 0.9775 - correlation_metric: 0.0225 - val_loss: 1.0011 - val_correlation_metric: -0.0011\n",
      "Epoch 5/10\n",
      "12771/12771 [==============================] - 154s 12ms/step - loss: 0.9836 - correlation_metric: 0.0164 - val_loss: 0.9767 - val_correlation_metric: 0.0233\n",
      "Epoch 6/10\n",
      "12771/12771 [==============================] - 154s 12ms/step - loss: 0.9792 - correlation_metric: 0.0208 - val_loss: 0.9755 - val_correlation_metric: 0.0245\n",
      "Epoch 7/10\n",
      "12771/12771 [==============================] - 154s 12ms/step - loss: 0.9891 - correlation_metric: 0.0109 - val_loss: 1.0034 - val_correlation_metric: -0.0034\n",
      "Epoch 8/10\n",
      "12771/12771 [==============================] - 154s 12ms/step - loss: 0.9819 - correlation_metric: 0.0181 - val_loss: 0.9788 - val_correlation_metric: 0.0212\n",
      "Epoch 9/10\n",
      "12771/12771 [==============================] - 154s 12ms/step - loss: 0.9860 - correlation_metric: 0.0140 - val_loss: 0.9970 - val_correlation_metric: 0.0030\n",
      "Epoch 10/10\n",
      "12771/12771 [==============================] - 154s 12ms/step - loss: 0.9915 - correlation_metric: 0.0085 - val_loss: 1.0047 - val_correlation_metric: -0.0047\n",
      "Test MSE: 0.988487, Test MAE: 0.011517\n",
      "   65/31927 [..............................] - ETA: 1:16"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 12:36:35.215067: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31927/31927 [==============================] - 71s 2ms/step\n",
      "Test Spearman Corr: -0.1522\n"
     ]
    }
   ],
   "source": [
    "# Full Model with Time-Series Split\n",
    "\n",
    "# Sample training\n",
    "\n",
    "\n",
    "feature_cols = ['cfo2cl', 'dta2ev', 'NNP_SD', 'ocfa4q', 'r_nta', 'roic4q', 'yoy_s','rk','return']\n",
    "df = df[feature_cols]\n",
    "# Train / test split\n",
    "\n",
    "# Sort by time variable\n",
    "df_sorted = df.sort_values(\"rk\").reset_index(drop=True)\n",
    "\n",
    "# Define split index (80% train, 20% test)\n",
    "split_idx = int(len(df_sorted) * 0.8)\n",
    "\n",
    "# Train and Test\n",
    "train = df_sorted.iloc[:split_idx]\n",
    "test  = df_sorted.iloc[split_idx:]\n",
    "\n",
    "X_train = train.drop(columns=[\"return\"])   # or your Y column name\n",
    "y_train = train[\"return\"]\n",
    "\n",
    "X_test = test.drop(columns=[\"return\"])\n",
    "y_test = test[\"return\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1)   # regression output: predicted return\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=correlation_loss,\n",
    "    metrics=[correlation_metric]  \n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ===========================\n",
    "# 5. Train the model\n",
    "# ===========================\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ===========================\n",
    "# 6. Evaluate on test set\n",
    "# ===========================\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Test MSE: {test_loss:.6f}, Test MAE: {test_mae:.6f}\")\n",
    "\n",
    "# ===========================\n",
    "# 7. Make predictions\n",
    "# ===========================\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "spearman_corr, pval = spearmanr(y_test, y_pred)\n",
    "print(f\"Test Spearman Corr: {spearman_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd1372c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31927/31927 [==============================] - 71s 2ms/step\n",
      "Test Spearman Corr: 0.1522\n"
     ]
    }
   ],
   "source": [
    "y_pred = -model.predict(X_test_scaled)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "spearman_corr, pval = spearmanr(y_test, y_pred)\n",
    "print(f\"Test Spearman Corr: {spearman_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "936be495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return    1.000000\n",
      "cfo2cl    0.015017\n",
      "ocfa4q    0.014627\n",
      "NNP_SD    0.010474\n",
      "mean      0.010446\n",
      "dta2ev    0.005456\n",
      "r_nta     0.004232\n",
      "code      0.003795\n",
      "roic4q   -0.001999\n",
      "yoy_s    -0.003611\n",
      "rk       -0.009992\n",
      "Name: return, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cols = ['cfo2cl','dta2ev','NNP_SD','ocfa4q','r_nta','roic4q','yoy_s']\n",
    "df_sample['mean'] = df_sample[cols].mean(axis=1)\n",
    "spearman_corr = df_sample.corr(method='spearman')['return'].sort_values(ascending=False)\n",
    "\n",
    "print(spearman_corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271533c",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ecedab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R²: 0.631778661756655\n",
      "Test  R²: -0.06530951033804189\n",
      "Test MSE: 0.02806300293695913\n",
      "Test Pearson corr(y, ŷ):  0.021340899220661166\n",
      "Test Spearman corr(y, ŷ): 0.026694496731058042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# -----------------------\n",
    "# 1. Select features\n",
    "# -----------------------\n",
    "feature_cols = ['cfo2cl', 'dta2ev', 'NNP_SD', 'ocfa4q', 'r_nta', 'roic4q', 'yoy_s','rk','return']\n",
    "df_sort = df[feature_cols]\n",
    "\n",
    "# -----------------------\n",
    "# 2. Time-series split\n",
    "# -----------------------\n",
    "df_sorted = df_sort.sort_values(\"rk\").reset_index(drop=True)\n",
    "\n",
    "split_idx = int(len(df_sorted) * 0.8)\n",
    "\n",
    "train = df_sorted.iloc[:split_idx]\n",
    "test  = df_sorted.iloc[split_idx:]\n",
    "\n",
    "X_train = train.drop(columns=[\"return\", \"rk\"])\n",
    "y_train = train[\"return\"]\n",
    "\n",
    "X_test  = test.drop(columns=[\"return\", \"rk\"])\n",
    "y_test  = test[\"return\"]\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------\n",
    "# 4. XGBoost model\n",
    "# -----------------------\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=2000,           # number of trees\n",
    "    learning_rate=0.01,         # shrinkage\n",
    "    max_depth=10,                # tree depth (controls complexity)\n",
    "    subsample=0.8,              # row subsample\n",
    "    colsample_bytree=0.8,       # feature subsample per tree\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# -----------------------\n",
    "# 5. Predictions\n",
    "# -----------------------\n",
    "y_pred_train = xgb_model.predict(X_train_scaled)\n",
    "y_pred_test  = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# -----------------------\n",
    "# 6. Evaluation\n",
    "# -----------------------\n",
    "print(\"Train R²:\", r2_score(y_train, y_pred_train))\n",
    "print(\"Test  R²:\", r2_score(y_test, y_pred_test))\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "# Correlation with return (Pearson & Spearman)\n",
    "pearson_corr = np.corrcoef(y_test, y_pred_test)[0, 1]\n",
    "spearman_corr, _ = spearmanr(y_test, y_pred_test)\n",
    "\n",
    "print(\"Test Pearson corr(y, ŷ): \", pearson_corr)\n",
    "print(\"Test Spearman corr(y, ŷ):\", spearman_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a615749",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# ==========================\n",
    "# 1. Select Features & Target\n",
    "# ==========================\n",
    "feature_cols = ['cfo2cl', 'dta2ev', 'NNP_SD', 'ocfa4q', 'r_nta', 'roic4q', 'yoy_s','rk','return']\n",
    "df_sort = df[feature_cols]\n",
    "\n",
    "# -----------------------\n",
    "# 2. Time-series split\n",
    "# -----------------------\n",
    "df_sorted = df_sort.sort_values(\"rk\").reset_index(drop=True)\n",
    "\n",
    "split_idx = int(len(df_sorted) * 0.8)\n",
    "\n",
    "train = df_sorted.iloc[:split_idx]\n",
    "test  = df_sorted.iloc[split_idx:]\n",
    "\n",
    "X_train = train.drop(columns=[\"return\", \"rk\"])\n",
    "y_train = train[\"return\"]\n",
    "\n",
    "X_test  = test.drop(columns=[\"return\", \"rk\"])\n",
    "y_test  = test[\"return\"]\n",
    "\n",
    "# ==================================\n",
    "# 3. Fit Random Forest Regressor\n",
    "# ==================================\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='auto',\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# ================================\n",
    "# 4. Predictions\n",
    "# ================================\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# ================================\n",
    "# 5. Evaluation Metrics\n",
    "# ================================\n",
    "\n",
    "# R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Pearson correlation\n",
    "corr = np.corrcoef(y_test, y_pred)[0, 1]\n",
    "\n",
    "# Spearman Rank Correlation (Rank-IC)\n",
    "rank_ic, _ = spearmanr(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest Performance:\")\n",
    "print(f\"R²:          {r2:.4f}\")\n",
    "print(f\"Correlation: {corr:.4f}\")\n",
    "print(f\"Rank-IC:     {rank_ic:.4f}\")\n",
    "\n",
    "# ================================\n",
    "# 6. Factor Importance\n",
    "# ================================\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(importances.sort_values(ascending=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
